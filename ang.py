# -*- coding: utf-8 -*-
"""Copia Evaluación_ang.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UPFb8gbKsNZ3Uf54NOLcBASma190bs6m

# Modelos de regresión

**Autor/es:**
+ Matías Aniñir
+ Samuel Garrido
+ Angelo López


**Fecha de Creación:** Octubre de 2024  
**Versión:** 1.0
"""

!wget https://www.dropbox.com/s/sst1u94436vqca6/demo_round_traces.csv

"""# Contexto del negocio

# Objetivo

Desarrollar modelos de regresión que permitan predecir ...

# Preparación del entorno
"""

# Commented out IPython magic to ensure Python compatibility.
# Importa las librerías a nuestro entorno de trabajo
import numpy as np
import pandas as pd
import seaborn as sb
import matplotlib.pyplot as plt
import seaborn as sns
import json
import pickle
# %matplotlib inline
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_log_error, r2_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

from sklearn.pipeline import Pipeline

"""# Carga de la data"""

data = pd.read_csv("demo_round_traces.csv", sep=';')

"""# Fase 2 - Comprensión de los datos

## Análisis de la distribución
"""

# Gráfica de la distribución
sns.histplot(data['RoundStartingEquipmentValue'])
plt.title("Distribución de valor del equipamiento del jugador al incio de la ronda", fontsize=16, fontweight="bold")
plt.xlabel("Precio del equipamiento", fontsize=14, fontweight="bold")
plt.ylabel("Frecuencia", fontsize=14, fontweight="bold")
plt.show()

"""Al observar el gráfico de la distribución de valor del equipamiento del jugador al incio de la ronda, resulta complicado identificar un sesgo a simple vista. Sin embargo, previamente se calcularon los siguientes estadísticos:
* **Media**: 3,778.11
* **Mediana**: 4,700.0
* **Moda**: 4,700

Dado que la media es menor que la mediana y la moda, se puede deducir que la distribución está sesgada hacia la izquierda. Esto sugiere que la mayoría de los jugadores comienzan las rondas con equipamientos de mayor valor, mientras que una menor cantidad de jugadores lo hacen con valores de equipamiento más bajos.

## Análisis de la correlación
"""

corr_matrix = data[data.describe().columns].corr()
corr_matrix["RoundStartingEquipmentValue"].sort_values(ascending=False)

"""Al analizar la correlación de la variable `RoundStartingEquipmentValue`, se encontró que la correlación más alta fue con `TeamStartingEquipmentValue` (0.922943), mientras que la menor correlación se observó con `PrimaryPistol` (-0.792876), la cual se consideró como una variable categórica, ya que solo presenta valores de 0 y 1. Sin embargo, dado que TeamStartingEquipmentValue es una consecuencia directa de `RoundStartingEquipmentValue` (al ser la suma del valor del equipamiento de todos los jugadores del equipo), decidimos excluirla para evitar redundancia en el modelo. En su lugar, seleccionamos las dos variables con las siguientes correlaciones más altas: `PrimaryAssaultRifle` (0.518780) y `RLethalGrenadesThrown` (0.438817), que ofrecen una relación más directa y significativa con el análisis del desempeño individual.

# Fase 3 - Preparación de los datos

## Selección de Variables

Para la creación de nuestros modelos de regresión hemos de seleccionar 2 variables independientes numéricas y una variable independiente categórica, además de nuestra variable objetivo.

A continuación presentaremos nuestras selecciones de variables y la justificación de por qué hemos elegido cada una:

### **Selección de Variable Objetivo**

1.   **RoundStartingEquipmentValue**

  *   Descripción de la variable: Valor del equipamiento llevado por el jugador al inicio de la ronda.
  *   Data type: *int64*
  *   Justificación: emos elegido RoundStartingEquipmentValue como nuestra variable objetivo porque representa una decisión estratégica importante en el juego. Predecir este valor puede ayudar a entender cómo los jugadores manejan su economía y cómo se preparan para cada ronda, lo cual es un aspecto crucial en Counter-Strike: GO.

### **Selección de Variables Independientes Númericas**

1. **PrimaryAssaultRifle**:

  *   Descripción de la variable: Porcentaje de uso del rifle de asalto como arma primaria.

  *   Data type: *int64*

  *   Justificación: Con una correlación de 0.518780, *PrimaryAssaultRifle* muestra una relación positiva moderada con *RoundStartingEquipmentValue*. Esto sugiere que el uso de rifles de asalto está relacionado con un mayor valor de equipamiento inicial, lo cual es lógico dado que los rifles de asalto son armas más caras.

2. **RLethalGrenadesThrown**:

  *   Descripción de la variable: Número de granadas letales lanzadas en la ronda.

  *   Data type: *int64*

  *   Justificación: Con una correlación de 0.438817, RLethalGrenadesThrown muestra una relación positiva moderada con RoundStartingEquipmentValue. Esto indica que los jugadores que compran más granadas letales tienden a tener un valor de equipamiento inicial más alto, lo cual es coherente con estrategias que involucran una inversión significativa en utilidades.

### **Selección de Variables Independientes Categórica**

1. **PrimaryPistol**:

  *   Descripción de la variable: Indica si el jugador usa una pistola como arma primaria
  *   Data type: *bool*
  *   Justificación: PrimaryPistol muestra una correlación negativa fuerte (-0.792876) con RoundStartingEquipmentValue, la hemos seleccionado como nuestra variable categórica. Esta fuerte correlación negativa es lógica, ya que usar una pistola como arma primaria generalmente indica una ronda de bajo presupuesto o una estrategia económica

## Selección de Técnica de Transformación

Para seleccionar la técnica de transformación de la variable categórica que mejor se adaptara a nuestras necesidades, aplicamos 7 técnicas vistas en clase. Para cada una de estas técnicas, creamos una copia del *dataframe* que contenía todas las variables seleccionadas y realizamos la transformación correspondiente. Posteriormente, aplicamos los modelos diseñados a cada una de estas copias para evaluar su rendimiento basándonos en las métricas de cada uno, con el objetivo de seleccionar el más eficiente. Los resultados son los siguientes

#### **Transformación con get_dummies 'manual'**

La transformación de la variable categórica PrimaryPistol usando el método de get_dummies de manera manual analizando el rendimiento de los modelos:

**Linear Regression**    - MAE: 766.60 - MSLE: 0.4697 - R² test: 0.6886 - R² train: 0.6879

**Decision Tree**        - MAE: 783.24 - MSLE: 0.4924 - R² test: 0.6618 - R² train: 0.7203

**Random Forest** - MAE: 762.46 - MSLE: 0.4720 - R² test: 0.6889 - R² train: 0.6965

#### **Transformación con get_dummies**

La transformación de la variable categórica PrimaryPistol usando el método de get_dummies y analizando el rendimiento en los modelos arrojó:

**Linear Regression** - MAE: 766.60 - MSLE: 0.4697 - R² test: 0.6886 - R² train: 0.6879

**Decision Tree** - MAE: 783.24 - MSLE: 0.4924 - R² test: 0.6618 - R² train: 0.7203

**Random Forest** - MAE: 762.46 - MSLE: 0.4720 - R² test: 0.6889 - R² train: 0.6965

#### **Transformación con LabelEncoder**

La transformación de la variable categórica PrimaryPistol usando el método de LabelEncoder y analizando el rendimiento en los modelos arrojó:

**Linear Regression** - MAE: 766.94 - MSLE: 0.4702 - R² test: 0.6886 - R² train: 0.6879

**Decision Tree** - MAE: 783.18 - MSLE: 0.4924 - R² test: 0.6619 - R² train: 0.7203

**Random Forest** - MAE: 762.46 - MSLE: 0.4720 - R² test: 0.6889 - R² train: 0.6965

#### **Transformación con OneHotEncoder**

La transformación de la variable categórica PrimaryPistol usando el método de OneHotEncoder y analizando el rendimiento en los modelos arrojó:

**Linear Regression**    - MAE: 766.79 - MSLE: 0.4698 - R² test: 0.6886 - R² train: 0.6879

**Decision Tree**        - MAE: 783.24 - MSLE: 0.4924 - R² test: 0.6618 - R² train: 0.7203

**Random Forest** - MAE: 762.46 - MSLE: 0.4720 - R² test: 0.6889 - R² train: 0.6965

#### **Transformación con Target Encoding**

La transformación de la variable categórica PrimaryPistol usando el método de Target Encoding y analizando el rendimiento en los modelos arrojó:

**Linear Regression**    - MAE: 766.94 - MSLE: 0.4702 - R² test: 0.6886 - R² train: 0.6879

**Decision Tree**        - MAE: 783.24 - MSLE: 0.4924 - R² test: 0.6618 - R² train: 0.7203

**Random Forest** - MAE: 762.46 - MSLE: 0.4720 - R² test: 0.6889 - R² train: 0.6965

#### **Transformación con Frequency Encoding**

La transformación de la variable categórica PrimaryPistol usando el método de Frequency Encoding y analizando el rendimiento en los modelos arrojó:

**Linear Regression**    - MAE: 766.94 - MSLE: 0.4702 - R² test: 0.6886 - R² train: 0.6879

**Decision Tree**        - MAE: 783.24 - MSLE: 0.4924 - R² test: 0.6618 - R² train: 0.7203

**Random Forest** - MAE: 762.46 - MSLE: 0.4720 - R² test: 0.6889 - R² train: 0.6965

#### **Transformación con Ordinal Encoding**

La transformación de la variable categórica PrimaryPistol usando el método de Ordinal Encoding y analizando el rendimiento en los modelos arrojó:

**Linear Regression**    - MAE: 766.94 - MSLE: 0.4702 - R² test: 0.6886 - R² train: 0.6879

**Decision Tree**        - MAE: 783.18 - MSLE: 0.4924 - R² test: 0.6619 - R² train: 0.7203

**Random Forest** - MAE: 762.46 - MSLE: 0.4720 - R² test: 0.6889 - R² train: 0.6965

#### **Conclusión**

Con base en la comparación de los resultados que arrojan estas métricas, pudimos observar que no se aprecian diferencias significativas en las magnitudes de los valores. Por lo tanto, la decisión de elegir un método sobre otro se basará en otro criterio. Como equipo, decidimos descartar aquellas técnicas que se utilizan principalmente para reducir la dimensionalidad, ya que esta variable solo puede poseer dos valores. Después de esta consideración, elegimos `LabelEncoder` debido a su fácil implementación. Tomamos esta decisión al no encontrar otro criterio de peso para la elección.

## Transformación de Variable Categórica

Es necesario hacer transformaciones de variables categóricas puesto que la mayoría de los algoritmos de aprendizaje automático supervisado trabajan con datos númericos, por lo que las variables categóricas necesitan ser convertidas en algo que pueda ser utilizada por los modelos que intentamos aplicar, ya que sino la variable afectaría negativamente en su rendimiento, por lo que hace necesario que esté en un formato númerico.

### Creación del dataframe en Base a las Variables Seleccionadas
"""

df_filtrado = data[['PrimaryAssaultRifle', 'RLethalGrenadesThrown', 'PrimaryPistol', 'RoundStartingEquipmentValue']]

df_filtrado

"""### Transformación con LabelEncoder"""

# Creamos una copia del dataframe para evitar errores con las demas alternativas
df_copia = df_filtrado.copy()
# Convertir la columna Survived a categórica
df_copia['PrimaryPistol'] = df_copia['PrimaryPistol'].astype('category')
# Obtiene las columnas a codificar
categorical_features = df_copia.describe(include='category').columns
# Usamos LabelEncoder
le = LabelEncoder()
for feature in categorical_features:
  df_copia[f'{feature}_codificado'] = le.fit_transform(df_copia[feature])

df_copia

"""# Fase 4 - Modelamiento

## Variante 1 - Uso sólo de variables cuantitativas
"""

models = {
    'Linear Regression': LinearRegression(),
    'Decision Tree': DecisionTreeRegressor(random_state=29),
    'Random Forest': RandomForestRegressor(
        random_state=29,
        max_depth=10,
        max_features='sqrt',
        min_samples_leaf=1,
        min_samples_split=10,
        n_estimators=300
    ),
}

# Divide en conjunto de características (X) y variable objetivo (y)
X = pd.DataFrame(df_copia[['PrimaryAssaultRifle', 'RLethalGrenadesThrown']])
y = df_copia['RoundStartingEquipmentValue']  # La variable objetivo

# Divide en conjunto de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=29)

print(f"{'Shape del set de entrenamiento':<30}:", X_train.shape)
print(f"{'Shape del set de prueba':<30}:", X_test.shape)

# Diccionario para guardar los modelos entrenados
history = {}

for name, model in models.items():
  pipeline = Pipeline(steps=[('model', model)])
  pipeline.fit(X_train, y_train)
  # Guardar el modelo entrenado en el diccionario
  y_pred = pipeline.predict(X_test)
  mae = mean_absolute_error(y_test, y_pred)
  msle = mean_squared_log_error(y_test, y_pred)
  r2 = r2_score(y_test, y_pred)
  score_train = model.score(X_train, y_train)
  print(f'{name:<20} - MAE: {mae:.2f} - MSLE: {msle:.4f} - R² test: {r2:.4f} - R² train: {score_train:.4f}')
  # Guarda resultados
  history[name] = [pipeline.named_steps['model'], pipeline.named_steps['model'].score(X_test, y_test),score_train, mae, msle]
  with open(f'{name}_variante1_model.pkl', 'wb') as file:
    pickle.dump(pipeline, file)

def visualiza_resultados(history : dict):
  # Extraer los nombres de los modelos y los resultados almacenados en 'history'
  model_names = list(history.keys())
  mae_values = [history[name][3] for name in model_names]  # MAE
  msle_values = [history[name][4] for name in model_names]  # MSLE
  r2_test_values = [history[name][1] for name in model_names]  # R² test
  r2_train_values = [history[name][2] for name in model_names]  # R² train

  # Crear subplots para los gráficos
  fig, axs = plt.subplots(1, 3, figsize=(18, 6))

  # Gráfico de MAE
  axs[0].barh(model_names, mae_values, color='skyblue')
  axs[0].set_title('MAE por Modelo', fontsize=14, fontweight="bold")
  axs[0].set_xlabel('MAE', fontsize=12, fontweight="bold")
  axs[0].invert_yaxis()

  # Gráfico de MSLE
  axs[1].barh(model_names, msle_values, color='#87ceeb')
  axs[1].set_title('MSLE por Modelo', fontsize=14, fontweight="bold")
  axs[1].set_xlabel('MSLE', fontsize=12, fontweight="bold")
  axs[1].invert_yaxis()

  # Gráfico de R² (test y train)
  width = 0.35  # Ancho de las barras
  x = np.arange(len(model_names))

  axs[2].bar(x - width/2, r2_train_values, width, label='R² Train', color='#4682b4')
  axs[2].bar(x + width/2, r2_test_values, width, label='R² Test', color='#5f9ea0')
  axs[2].set_xticks(x)
  axs[2].set_xticklabels(model_names, rotation=45)
  axs[2].set_title('R² por Modelo', fontsize=14, fontweight="bold")
  axs[2].set_ylabel('R² Score', fontsize=12, fontweight="bold")
  axs[2].legend()

  # Agregar el supertítulo
  plt.suptitle('Comparación de Modelos de Regresión', fontsize=18, fontweight="bold")

  plt.tight_layout(rect=[0, 0, 1, 0.95])
  plt.show()

visualiza_resultados(history)

"""## **Mejor Modelo Seleccionado:** Random Forest
### **Métricas:**
- **MAE:** 1062.68
- **MSLE:** 0.8488
- **R² Test**: 0.4364
- **R² Train:** 0.4366

### **Análisis:**
El modelo de Random Forest demostró el mejor desempeño en comparación con los otros dos modelos, con un MAE de 1062.68, el más bajo de todos. El MSLE de 0.8488 también fue el más bajo, lo que sugiere que este modelo es más preciso en términos de errores logarítmicos. El R² fue de 0.4364 en el conjunto de prueba, lo que indica que puede explicar aproximadamente el 43.64% de la variabilidad en la variable objetivo, convirtiéndolo en el mejor modelo de los tres. El R² en el conjunto de entrenamiento fue muy cercano, con 0.4366, lo que indica una excelente capacidad de generalización sin sobreajuste.

## Variante 2 - Uso de variables cuantitativas y categórica
"""

models = {
    'Linear Regression': LinearRegression(),
    'Decision Tree': DecisionTreeRegressor(random_state=29),
    'Random Forest': RandomForestRegressor(
        random_state=29,
        max_depth=10,
        max_features='sqrt',
        min_samples_leaf=1,
        min_samples_split=10,
        n_estimators=300
    ),
}

# Divide en conjunto de características (X) y variable objetivo (y)
X_new = pd.DataFrame(df_copia[['PrimaryAssaultRifle', 'RLethalGrenadesThrown', 'PrimaryPistol']])
y_new = df_copia['RoundStartingEquipmentValue']  # La variable objetivo

# Divide en conjunto de entrenamiento y prueba
X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_new, y_new,
                                                                    test_size=0.2,
                                                                    random_state=29)

# Diccionario para guardar los modelos entrenados

history_x = {}
for name, model in models.items():
    pipeline = Pipeline(steps=[('model', model)])
    pipeline.fit(X_train_new, y_train_new)
    # Guardar el modelo entrenado en el diccionario

    y_pred = pipeline.predict(X_test_new)
    mae = mean_absolute_error(y_test_new, y_pred)
    msle = mean_squared_log_error(y_test_new, y_pred)
    r2 = r2_score(y_test_new, y_pred)
    score_train = model.score(X_train_new, y_train_new)
    print(f'{name:<20} - MAE: {mae:.2f} - MSLE: {msle:.4f} - R² test: {r2:.4f} - R² train: {score_train:.4f}')
    # Guarda resultados
    history_x[name] = [pipeline.named_steps['model'], pipeline.named_steps['model'].score(X_test_new, y_test_new), score_train, mae, msle]

visualiza_resultados(history_x)

"""##**Mejor Modelo Seleccionado:** Random Forest
## **Métricas:**
- **MAE:** 762.46

- **MSLE:** 0.4720

- **R² Test:** 0.6889

- **R² Train:** 0.6965


## **Análisis:**
El modelo de Random Forest obtuvo el MAE más bajo, con un valor de 762.46, lo que sugiere que es el modelo más preciso en términos de error absoluto medio entre los tres. El MSLE fue de 0.4720, muy similar al valor obtenido con la regresión lineal, lo que indica que este modelo también es eficaz en capturar la relación entre las variables. El R² en el conjunto de prueba fue de 0.6889, el valor más alto entre los tres modelos, lo que indica que el Random Forest explica el 68.89% de la variabilidad en la variable objetivo, posicionándolo como el modelo más robusto para la predicción. El R² en el conjunto de entrenamiento fue de 0.6965, lo que muestra que el modelo tiene una buena capacidad de generalización y no está sobreajustado.

# Fase 5 - Evaluación
"""

def get_bestModel(history : dict, metric = "R2", mayor = True):
  # Inicializar una variable para almacenar el mejor valor
  best_value = float('-inf') if mayor else float('+inf')

  # Selecciona el índice de la métrica solicitada
  dict_metrics = {"MAE" : 3, "R2" : 1, "MSLE" : 4}
  num_metric = dict_metrics[metric.upper()]
  # Recorrer el diccionario
  for modelo, data in history.items():

    # Comparar valor de la métrica encontrada
    if mayor and data[num_metric] > best_value:
        best_value = data[num_metric]
        best = data[0]
        best_name = modelo
    if not mayor and data[num_metric] < best_value:
        best_value = data[num_metric]
        best = data[0]
        best_name = modelo

  return best, best_value, best_name

"""## Variante 1 - Uso sólo de variables cuantitativas"""

best_model, best_score, name = get_bestModel(history)

print("El mejor rendimiento, considerando R² es: {0:.2%} y le corresponde a\n\t{1} -> {2}".format(best_score, best_model, name))

"""## Variante 2 - Uso de variables cuantitativas y categórica"""

best_model_x, best_score_x, name_x = get_bestModel(history_x)
print("El mejor rendimiento, considerando R² es: {0:.2%} y le corresponde a {1} -> {2}".format(best_score_x,
                                                                                               best_model_x,
                                                                                               name_x))

"""Se ha elegido el $R^{2}$ como métrica prioritaria debido a nuestra preferencia por un modelo que ofrezca una comprensión más profunda de los datos. En situaciones donde las decisiones tácticas pueden impactar directamente en el resultado de una partida, un modelo con un $R^{2}$ elevado proporciona una base sólida y confiable para la toma de decisiones informadas. Esta elección nos permite no solo confiar en las predicciones del modelo, sino también en su capacidad para explicar la variabilidad de los resultados, su relevancia en la formulación de estrategias y su utilidad en comparación con otras métricas.

Al centrarnos en $R^{2}$, garantizamos que nuestro análisis no se limite únicamente a obtener predicciones precisas, sino que también se enfoque en entender las dinámicas que influyen en el rendimiento en Counter-Strike: GO. De este modo, podemos desarrollar enfoques más informados y efectivos para optimizar el desempeño de los jugadores y las tácticas del equipo.

# Fase 6 - Deployment

## Variante 1 - Uso sólo de variables cuantitativas
"""

# Obtiene la cantidad de variables independientes con las que fue entrenado el modelo
best_model.n_features_in_

# Obtiene el nombre de las variables independientes
best_model.feature_names_in_

data_new = [90, 5]
X_data = pd.DataFrame(np.array(data_new).reshape(1,-1), columns=X_train.columns)

prediction = best_model.predict(X_data)[0]
print("\033[1m El valor del equipamiento del jugador al inicio de la ronda considerando un \n\tPorcentaje de uso de rifles de asalto de {0} y \n\tcon {1} granadas letales de la ronda es  ${1:.2f}".format(data_new[0],data_new[1],prediction))

"""## Variante 2 - Uso de variables cuantitativas y categórica"""

# Obtiene el nombre de las variables independientes
best_model_x.feature_names_in_

#Pasar la variables en orden, JSON?
data_new = [90, 0, 0]
data_new

X_data_new = pd.DataFrame(np.array(data_new).reshape(1,-1), columns=X_train_new.columns)

prediction = best_model_x.predict(X_data_new)[0]
print("\033[1m El valor del equipamiento del jugador al inicio de la ronda considerando un \n\tPorcentaje de uso de rifles de asalto de {0}%, \n\tGranadas letales de la ronda de {1} y \n\tuso o no uso de pistola en la ronda de {2} es ${3:.2f}".format(data_new[0],
                                                                                                                                    data_new[1], data_new[2], prediction))

"""# Pregunta final

¿Qué modelo recomendaría utilizar para cumplir con el objetivo propuesto al inicio? Deberá justificar su respuesta
"""
